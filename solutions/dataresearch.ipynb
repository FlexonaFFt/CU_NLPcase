{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f213d61",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "!pip install -q transformers torch datasets pandas scikit-learn accelerate bitsandbytes peft fuzzywuzzy python-levenshtein"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11c665ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM, BitsAndBytesConfig\n",
    "from datasets import Dataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import f1_score\n",
    "import time\n",
    "import re\n",
    "from fuzzywuzzy import fuzz \n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44c710e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv('../data/train.csv')\n",
    "test_df = pd.read_csv('../data/test.csv')\n",
    "with open('categories.txt', 'r', encoding='utf-8') as f:\n",
    "    categories = [line.strip() for line in f.readlines()]\n",
    "\n",
    "print(f\"Категории: {categories}\")\n",
    "print(f\"Train shape: {train_df.shape}\")\n",
    "print(f\"Test shape: {test_df.shape}\")\n",
    "\n",
    "# Осмотр train\n",
    "print(\"\\nПримеры из train:\")\n",
    "print(train_df['text'].head(3).tolist())\n",
    "\n",
    "# Проверка на NaN и дубликаты\n",
    "print(f\"NaN в train: {train_df.isnull().sum().sum()}\")\n",
    "train_df.drop_duplicates(subset=['text'], inplace=True)\n",
    "print(f\"Train после удаления дубликатов: {train_df.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78104fd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_text(text):\n",
    "    if pd.isna(text):\n",
    "        return \"\"\n",
    "    text = text.lower()\n",
    "    text = re.sub(r'\\s+', ' ', text.strip())\n",
    "    text = re.sub(r'[^\\w\\s.,!?—–-]', ' ', text)\n",
    "    if len(text) < 10:\n",
    "        return \"\"\n",
    "    return text\n",
    "\n",
    "# Применение предобработки\n",
    "train_df['text_clean'] = train_df['text'].apply(preprocess_text)\n",
    "test_df['text_clean'] = test_df['text'].apply(preprocess_text)\n",
    "\n",
    "# Удаление пустых после очистки\n",
    "train_df = train_df[train_df['text_clean'] != ''].reset_index(drop=True)\n",
    "test_df = test_df[test_df['text_clean'] != ''].reset_index(drop=True)\n",
    "\n",
    "print(f\"Train после предобработки: {train_df.shape}\")\n",
    "print(\"\\nПримеры очищенных текстов:\")\n",
    "print(train_df['text_clean'].head(3).tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b98583c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Модель для разметки \n",
    "model_name = \"microsoft/Phi-3-mini-4k-instruct\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "quant_config = BitsAndBytesConfig(\n",
    "    load_in_4bit=True,\n",
    "    bnb_4bit_compute_dtype=torch.float16,\n",
    "    bnb_4bit_use_double_quant=True\n",
    ")\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "base_model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_name,\n",
    "    quantization_config=quant_config,\n",
    "    device_map=\"auto\" if device == \"cuda\" else None,\n",
    "    trust_remote_code=True\n",
    ")\n",
    "\n",
    "print(f\"Модель загружена на {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86a70c57",
   "metadata": {},
   "outputs": [],
   "source": [
    "few_shot_examples = \"\"\"\n",
    "Пример 1: \"Футболка хорошего качества, но велика.\" -> одежда\n",
    "Пример 2: \"Кроссовки не подошли по размеру.\" -> обувь\n",
    "Пример 3: \"Холодильник шумит сильно.\" -> бытовая техника\n",
    "Пример 4: \"Тарелки красивые, но бьются.\" -> посуда\n",
    "Пример 5: \"Полотенце мягкое, приятное.\" -> текстиль\n",
    "Пример 6: \"Игрушка для ребенка сломалась.\" -> товары для детей\n",
    "Пример 7: \"Серьги подделка, цвет не тот.\" -> украшения и аксессуары\n",
    "Пример 8: \"Телефон не заряжается.\" -> электроника\n",
    "Пример 9: \"Заказ не пришел, деньги не вернули.\" -> нет товара\n",
    "\"\"\"\n",
    "\n",
    "def classify_review(text, model, tokenizer, categories, few_shot=few_shot_examples):\n",
    "    prompt = f\"\"\"Ты классификатор отзывов по категориям товаров. Используй только одну категорию из списка: {', '.join(categories)}.\n",
    "{few_shot}\n",
    "Отзыв: \"{text}\"\n",
    "Категория:\"\"\"\n",
    "    \n",
    "    inputs = tokenizer(prompt, return_tensors=\"pt\", padding=True, truncation=True, max_length=512).to(device)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        outputs = model.generate(\n",
    "            **inputs,\n",
    "            max_new_tokens=20,\n",
    "            temperature=0.1,\n",
    "            do_sample=True,\n",
    "            pad_token_id=tokenizer.eos_token_id\n",
    "        )\n",
    "    \n",
    "    generated = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "    pred = generated.split(\"Категория:\")[-1].strip().lower()\n",
    "    \n",
    "    # Fuzzy matching для лучшей точности\n",
    "    best_match = max(categories, key=lambda cat: fuzz.ratio(pred, cat.lower()))\n",
    "    confidence = fuzz.ratio(pred, best_match.lower()) / 100.0\n",
    "    \n",
    "    return best_match if confidence > 0.6 else \"нет товара\"  \n",
    "\n",
    "# Тест на одном примере\n",
    "test_text = train_df['text_clean'].iloc[0]\n",
    "pred = classify_review(test_text, base_model, tokenizer, categories)\n",
    "print(f\"Отзыв: {test_text[:100]}...\")\n",
    "print(f\"Предсказание: {pred}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce96fb6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 50\n",
    "train_labeled = []\n",
    "\n",
    "start_time_total = time.time()\n",
    "for i in range(0, len(train_df), batch_size):\n",
    "    batch = train_df['text_clean'][i:i+batch_size]\n",
    "    batch_preds = []\n",
    "    \n",
    "    batch_start = time.time()\n",
    "    for text in batch:\n",
    "        pred = classify_review(text, base_model, tokenizer, categories)\n",
    "        batch_preds.append(pred)\n",
    "    \n",
    "    train_labeled.extend(batch_preds)\n",
    "    elapsed_batch = time.time() - batch_start\n",
    "    print(f\"Батч {i//batch_size + 1}: {len(batch)} примеров за {elapsed_batch:.2f}с (ср. {elapsed_batch/len(batch):.2f}с/пример)\")\n",
    "    torch.cuda.empty_cache() if device == \"cuda\" else None\n",
    "\n",
    "total_time = time.time() - start_time_total\n",
    "print(f\"Общее время разметки: {total_time:.2f}с (ср. {total_time/len(train_df):.2f}с/пример)\")\n",
    "\n",
    "train_df_labeled = train_df.copy()\n",
    "train_df_labeled['label'] = train_labeled\n",
    "train_df_labeled[['text_clean', 'label']].to_csv('train_labeled.csv', index=False)\n",
    "print(f\"Сохранено в train_labeled.csv: {train_df_labeled.shape}\")\n",
    "print(\"\\nРаспределение классов:\")\n",
    "print(train_df_labeled['label'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1ced21b",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Распределение по категориям:\")\n",
    "label_counts = train_df_labeled['label'].value_counts()\n",
    "print(label_counts)\n",
    "\n",
    "\n",
    "for cat in categories[:3]:  \n",
    "    examples = train_df_labeled[train_df_labeled['label'] == cat]['text_clean'].head(1).tolist()\n",
    "    if examples:\n",
    "        print(f\"\\n{cat}: {examples[0][:100]}...\")\n",
    "\n",
    "print(\"\\nГотово! Теперь можно перейти к fine-tune в отдельном notebook'e, используя train_labeled.csv\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
