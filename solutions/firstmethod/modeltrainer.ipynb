{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c311d36",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "!pip install -q transformers torch accelerate bitsandbytes fuzzywuzzy python-levenshtein pandas scikit-learn peft"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b06cb96c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM, BitsAndBytesConfig, Trainer, TrainingArguments, DataCollatorForLanguageModeling\n",
    "from peft import LoraConfig, get_peft_model\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "from fuzzywuzzy import fuzz\n",
    "import time\n",
    "import re\n",
    "import logging\n",
    "\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "logger = logging.getLogger(__name__)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84c81ac9",
   "metadata": {},
   "source": [
    "## Аугментации "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37dc9ae0",
   "metadata": {},
   "outputs": [],
   "source": [
    "categories = ['бытовая техника', 'обувь', 'одежда', 'посуда', 'текстиль', 'товары для детей', 'украшения и аксессуары', 'электроника', 'нет товара']\n",
    "train_df = pd.read_csv('train_labeled.csv')  # До аугментации\n",
    "\n",
    "def preprocess_text(text):\n",
    "    if pd.isna(text):\n",
    "        return \"\"\n",
    "    text = text.lower()\n",
    "    text = re.sub(r'\\s+', ' ', text.strip())\n",
    "    text = re.sub(r'[^\\w\\s.,!?—–-]', ' ', text)\n",
    "    if len(text) < 10:\n",
    "        return \"\"\n",
    "    return text\n",
    "\n",
    "train_df['text_clean'] = train_df['text_clean'].apply(preprocess_text)\n",
    "train_df = train_df[train_df['text_clean'] != ''].reset_index(drop=True)\n",
    "label_counts = train_df['label_final'].value_counts()\n",
    "rare_classes = [cat for cat in categories if label_counts.get(cat, 0) < 100]\n",
    "print(f\"Редкие классы: {rare_classes}\")\n",
    "\n",
    "if rare_classes:\n",
    "    model_name2 = \"sberbank-ai/rugpt3large_based_on_gpt2\"\n",
    "    tokenizer2 = AutoTokenizer.from_pretrained(model_name2)\n",
    "    tokenizer2.pad_token = tokenizer2.eos_token\n",
    "    base_model2 = AutoModelForCausalLM.from_pretrained(model_name2, torch_dtype=torch.float16).to(\"cuda\")\n",
    "    \n",
    "    augmented = []\n",
    "    for cat in rare_classes:\n",
    "        for _ in range(150):  # 150 примеров на класс\n",
    "            prompt = f\"\"\"Генерируй короткий отзыв на русском о товаре из категории '{cat}'. \n",
    "            Учитывай стиль реальных отзывов: упомяни качество, размер, доставку или недостатки.\n",
    "            Пример: 'Кроссовки удобные, но быстро износились.'\"\"\"\n",
    "            inputs = tokenizer2(prompt, return_tensors=\"pt\", truncation=True, max_length=256).to(\"cuda\")\n",
    "            with torch.no_grad():\n",
    "                outputs = base_model2.generate(**inputs, max_new_tokens=50, temperature=0.7, do_sample=True)\n",
    "            synth_text = tokenizer2.decode(outputs[0], skip_special_tokens=True).split(\"Пример:\")[-1].strip()\n",
    "            augmented.append({'text_clean': synth_text, 'label_final': cat})\n",
    "    \n",
    "    aug_df = pd.DataFrame(augmented)\n",
    "    train_df = pd.concat([train_df, aug_df], ignore_index=True)\n",
    "    train_df.to_csv('train_labeled_augmented.csv', index=False)\n",
    "    print(\"Аугментированный датасет сохранён как 'train_labeled_augmented.csv'\")\n",
    "    print(\"Распределение после аугментации:\")\n",
    "    print(train_df['label_final'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ae0ae9c",
   "metadata": {},
   "source": [
    "## Разделение датасета (train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bf60b90",
   "metadata": {},
   "source": [
    "Хочу попробовать высчитывать weighted F1 на тренировочной выборке"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f6ef215",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data, val_data = train_test_split(\n",
    "    train_df,\n",
    "    test_size=0.2,\n",
    "    stratify=train_df['label_final'],\n",
    "    random_state=42\n",
    ")\n",
    "print(f\"Train size: {len(train_data)}, Validation size: {len(val_data)}\")\n",
    "print(\"Validation распределение:\")\n",
    "print(val_data['label_final'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07c95b41",
   "metadata": {},
   "source": [
    "## Модель"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f74dcf53",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "quant_config = BitsAndBytesConfig(load_in_4bit=True, bnb_4bit_compute_dtype=torch.float16)\n",
    "\n",
    "model_name = \"ai-forever/mGPT\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "base_model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_name,\n",
    "    quantization_config=quant_config,\n",
    "    device_map=\"auto\",\n",
    "    trust_remote_code=False,\n",
    "    torch_dtype=torch.float16\n",
    ")\n",
    "print(f\"Модель загружена на {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8c4e560",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_data(df, tokenizer):\n",
    "    texts = [f\"Отзыв: {row['text_clean']}\\nКатегория: {row['label_final']}\" for _, row in df.iterrows()]\n",
    "    encodings = tokenizer(texts, truncation=True, padding=True, max_length=512, return_tensors=\"pt\")\n",
    "    return encodings\n",
    "\n",
    "train_encodings = prepare_data(train_data, tokenizer)\n",
    "val_encodings = prepare_data(val_data, tokenizer)\n",
    "\n",
    "class CustomDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, encodings):\n",
    "        self.encodings = encodings\n",
    "    def __getitem__(self, idx):\n",
    "        item = {key: val[idx] for key, val in self.encodings.items()}\n",
    "        item['labels'] = item['input_ids'].clone()\n",
    "        return item\n",
    "    def __len__(self):\n",
    "        return len(self.encodings['input_ids'])\n",
    "\n",
    "train_dataset = CustomDataset(train_encodings)\n",
    "val_dataset = CustomDataset(val_encodings)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2bb46e6",
   "metadata": {},
   "source": [
    "## Обучение"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00604ef6",
   "metadata": {},
   "outputs": [],
   "source": [
    "lora_config = LoraConfig(\n",
    "    r=8,\n",
    "    lora_alpha=16,\n",
    "    target_modules=[\"c_attn\", \"c_proj\"],\n",
    "    lora_dropout=0.1,\n",
    "    bias=\"none\",\n",
    "    task_type=\"CAUSAL_LM\"\n",
    ")\n",
    "model = get_peft_model(base_model, lora_config)\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./lora_output\",\n",
    "    num_train_epochs=3,\n",
    "    per_device_train_batch_size=8,\n",
    "    per_device_eval_batch_size=8,\n",
    "    warmup_steps=100,\n",
    "    weight_decay=0.01,\n",
    "    logging_dir='./logs',\n",
    "    logging_steps=10,\n",
    "    evaluation_strategy=\"steps\",\n",
    "    eval_steps=100,\n",
    "    save_strategy=\"steps\",\n",
    "    save_steps=100,\n",
    "    load_best_model_at_end=True,\n",
    "    fp16=True\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=val_dataset,\n",
    "    data_collator=DataCollatorForLanguageModeling(tokenizer=tokenizer, mlm=False)\n",
    ")\n",
    "\n",
    "start_time = time.time()\n",
    "trainer.train()\n",
    "model.save_pretrained(\"./lora_mgpt_finetuned\")\n",
    "tokenizer.save_pretrained(\"./lora_mgpt_finetuned\")\n",
    "print(f\"Обучение завершено. Время: {time.time() - start_time:.2f}с\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "039459f4",
   "metadata": {},
   "source": [
    "## Промежуточная оценка"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2857def",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(model, tokenizer, df):\n",
    "    preds = []\n",
    "    prompt_template = \"\"\"Ты классификатор отзывов по категориям: {categories}.\n",
    "Шаги:\n",
    "1. Прочитай отзыв.\n",
    "2. Ищи прямые (футболка → одежда) или косвенные признаки (ткань → одежда, доставка → нет товара).\n",
    "3. Выведи только категорию.\n",
    "\n",
    "Примеры:\n",
    "1. Отзыв: \"Футболка велика, ткань синтетика.\" Категория: одежда\n",
    "2. Отзыв: \"Кроссовки жмут.\" Категория: обувь\n",
    "3. Отзыв: \"Заказ не пришёл.\" Категория: нет товара\n",
    "4. Отзыв: \"Ткань тонкая, швы кривые.\" Категория: одежда\n",
    "5. Отзыв: \"Телефон быстро садится.\" Категория: электроника\n",
    "\n",
    "Отзыв: \"{text}\"\n",
    "Категория:\"\"\"\n",
    "    \n",
    "    for text in df['text_clean']:\n",
    "        prompt = prompt_template.format(categories=', '.join(categories), text=text)\n",
    "        inputs = tokenizer(prompt, return_tensors=\"pt\", truncation=True, max_length=512).to(device)\n",
    "        with torch.no_grad():\n",
    "            outputs = model.generate(**inputs, max_new_tokens=10, temperature=0.05)\n",
    "        pred = tokenizer.decode(outputs[0], skip_special_tokens=True).split(\"Категория:\")[-1].strip().lower()\n",
    "        best_match = max(categories, key=lambda cat: fuzz.ratio(pred, cat.lower()))\n",
    "        preds.append(best_match)\n",
    "    \n",
    "    report = classification_report(df['label_final'], preds, output_dict=True, zero_division=0)\n",
    "    return report\n",
    "\n",
    "report = evaluate_model(model, tokenizer, val_data)\n",
    "print(\"Промежуточный Weighted F1 (validation):\", report['weighted avg']['f1-score'])\n",
    "print(\"Полный отчёт по классам:\")\n",
    "for label, metrics in report.items():\n",
    "    if label in categories:\n",
    "        print(f\"{label}: Precision={metrics['precision']:.2f}, Recall={metrics['recall']:.2f}, F1={metrics['f1-score']:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7298ef84",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = pd.read_csv('test.csv')\n",
    "test_df['text_clean'] = test_df['text'].apply(preprocess_text)\n",
    "test_df = test_df[test_df['text_clean'] != ''].reset_index(drop=True)\n",
    "\n",
    "report = evaluate_model(model, tokenizer, test_df)\n",
    "print(\"Финальный Weighted F1 (test):\", report['weighted avg']['f1-score'])\n",
    "print(\"Полный отчёт по классам:\")\n",
    "for label, metrics in report.items():\n",
    "    if label in categories:\n",
    "        print(f\"{label}: Precision={metrics['precision']:.2f}, Recall={metrics['recall']:.2f}, F1={metrics['f1-score']:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5af1dd26",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nПервые 5 строк train (проверка корректности):\")\n",
    "first_five = train_df[['text_clean', 'label_final']].head(5)\n",
    "for _, row in first_five.iterrows():\n",
    "    text = row['text_clean']\n",
    "    label = row['label_final']\n",
    "    prompt = prompt_template.format(categories=', '.join(categories), text=text)\n",
    "    inputs = tokenizer(prompt, return_tensors=\"pt\", truncation=True, max_length=512).to(device)\n",
    "    with torch.no_grad():\n",
    "        outputs = model.generate(**inputs, max_new_tokens=10, temperature=0.05)\n",
    "    pred = tokenizer.decode(outputs[0], skip_special_tokens=True).split(\"Категория:\")[-1].strip().lower()\n",
    "    best_match = max(categories, key=lambda cat: fuzz.ratio(pred, cat.lower()))\n",
    "    print(f\"Отзыв: {text[:50]}...\\nИстинная метка: {label}\\nПредсказанная: {best_match}\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
